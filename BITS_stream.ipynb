{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a567a9e-4ac2-47d9-81f0-332e80609b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the index\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "import os\n",
    "\n",
    "# PLEASE MAKE SURE YOU SET THE OPENAI KEY otherwise nothing will work.\n",
    "\n",
    "# import langchain \n",
    "#langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8efbd4-32d6-4b80-8853-867c273f0b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found index - loading - this may take a few seconds\n",
      "<llama_index.indices.vector_store.base.VectorStoreIndex object at 0x2a9ca2c70>\n"
     ]
    }
   ],
   "source": [
    "project_path=\"./bioe80\"\n",
    "storage_path=project_path+\"/storage\"\n",
    "\n",
    "if os.path.isfile(project_path+\"/storage/index_store.json\") :\n",
    "    print(\"Found index - loading - this may take a few seconds\")\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=storage_path)\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context)\n",
    "else :\n",
    "\tprint(\"please generate an index first\")\n",
    "\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079f0f10-8ab0-46c0-a9b3-9af9e9005ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"BITS\",\n",
    "        func=lambda q: str(index.as_query_engine().query(q)),\n",
    "        description=\"useful for when you want to answer questions about your class. The input to this tool should be a complete english sentence.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0376db3d-b707-4687-b903-724c481a4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=512, model_name=\"gpt-3.5-turbo\") # gpt-3.5-turbo || gpt-4\n",
    "# llm = ChatOpenAI(temperature=0, max_tokens=512, model_name=\"gpt-4\") # gpt-3.5-turbo || gpt-4\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acb685b-822e-4a4c-ae78-27f05fd6a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Hello Drew! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Drew! How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Hi, I am Drew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f220e7c6-8c28-4417-84ec-135612f1d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: BITS\n",
      "Action Input: Summarize the BioE80 course\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "BioE80 is an introductory course to bioengineering, which focuses on the systematic engineering of living systems to benefit all people and the planet. The course aims to help students learn ways of thinking about engineering living matter, empower them to explore and do bioengineering starting from DNA, and become more capable of learning and explaining bioengineering to themselves and others. Additionally, the course seeks to enable students to devise and express their wishes for bioengineering as might be made true by or before 2030, and to develop practical plans for making their wishes real.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cross_query_str = \"Please summarize the BioE80 course\"\n",
    "response = agent_chain.run(\"Please summarize the BioE80 course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3607f732-0056-4fe1-8dfb-83ba7d6f08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: BITS\n",
      "Action Input: Will Bioe80 be offered again next year?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "It is not possible to answer this question with the given context information.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cross_query_str = \"Will Bioe80 be offered again next year?\"\n",
    "response = agent_chain.run(input=cross_query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f69bb9a-e432-45d3-aeff-27d35ab95fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: BITS\n",
      "Action Input: \"What's my name?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "Your name is Ahmed Best.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYour name is Ahmed Best.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate memory\n",
    "agent_chain.run(input=\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39a4e83-462b-4f5e-9e98-02ead5b18521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=512, model_name=\"gpt-3.5-turbo\") # gpt-4\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada35825-0e5a-4465-8750-6aaaeabdf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     text_input = input(\"User: \")\n",
    "#     response = agent_chain.run(input=text_input)\n",
    "#     print(f\"Agent: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7fdb78b-777a-473d-93f4-a22af9cf680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 12:27:43.480 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/jan/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "import streamlit as st\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "#llm = ChatOpenAI(temperature=0, max_tokens=512, model_name=\"gpt-3.5-turbo\") # gpt-4\n",
    "\n",
    "llm = OpenAI(temperature=0, streaming=True)\n",
    "#tools = load_tools([\"ddg-search\"])\n",
    "#already defined\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory, verbose=True)\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st_callback = StreamlitCallbackHandler(st.container())\n",
    "        response = agent.run(prompt, callbacks=[st_callback])\n",
    "        st.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a851a-d5ca-4210-be2c-82cf96bf4853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
